{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85a1fd84-04c7-4025-a50b-150a95b1e152",
   "metadata": {},
   "source": [
    "# Notebook ICD - 17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e517e961-c76e-4bf5-a115-7f816df754b9",
   "metadata": {},
   "source": [
    "### Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547f20de-5044-4a65-9a21-208f292c10cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, StackingClassifier, VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b094997-7207-4edf-aee3-2b7c26cd6a58",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "Remembering Iris dataset from `scikit-learn` contains 150 samples of iris flowers, classified into three species. Each sample has four features: sepal length, sepal width, petal length, and petal width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1930cc3c-66ce-487e-9b93-df0f084bebfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62476453-ae20-4587-b282-a7a11102e49a",
   "metadata": {},
   "source": [
    "### Individual classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6516d58-29b4-4b8d-b709-71db7191ef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base classifiers\n",
    "classifiers = {\n",
    "    'CART': DecisionTreeClassifier(),\n",
    "    'GNB': GaussianNB(),\n",
    "    'kNN': KNeighborsClassifier(),\n",
    "    'SVM': SVC(kernel='linear', probability=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeda3d39-c3e6-4718-bea2-ea3bd51c4fd8",
   "metadata": {},
   "source": [
    "### Define Ensemble classifiers\n",
    "\n",
    "Gradient Boosting builds an additive model in a forward stage-wise fashion; it allows for the optimization of arbitrary differentiable loss functions. In each stage n_classes_ regression trees are fit on the negative gradient of the loss function, e.g. binary or multiclass log loss. Binary classification is a special case where only a single regression tree is induced.\n",
    "\n",
    "A Bagging classifier is an ensemble meta-estimator that fits base classifiers each on random subsets of the original dataset and then aggregate their individual predictions (either by voting or by averaging) to form a final prediction. Such a meta-estimator can typically be used as a way to reduce the variance of a black-box estimator (e.g., a decision tree), by introducing randomization into its construction procedure and then making an ensemble out of it.\n",
    "\n",
    "Stacked generalization consists in stacking the output of individual estimator and use a classifier to compute the final prediction. Stacking allows to use the strength of each individual estimator by using their output as input of a final estimator. Note that estimators_ are fitted on the full X while final_estimator_ is trained using cross-validated predictions of the base estimators using cross_val_predict.\n",
    "\n",
    "The idea behind the VotingClassifier is to combine conceptually different machine learning classifiers and use a majority vote or the average predicted probabilities (soft vote) to predict the class labels. Such a classifier can be useful for a set of equally well performing models in order to balance out their individual weaknesses. In majority voting, the predicted class label for a particular sample is the class label that represents the majority (mode) of the class labels predicted by each individual classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6dd102-cf8f-4f1c-b2d9-2699bbfc9c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ensemble classifiers\n",
    "ensemble_classifiers = {\n",
    "    'Bagging': BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=10),\n",
    "    'Boosting': AdaBoostClassifier(estimator=DecisionTreeClassifier(), n_estimators=10),\n",
    "    'Stacking': StackingClassifier(estimators=[('cart', DecisionTreeClassifier()), ('svm', SVC(probability=True))], final_estimator=RandomForestClassifier()),\n",
    "    'Voting': VotingClassifier(estimators=[('cart', DecisionTreeClassifier()), ('gnb', GaussianNB()), ('knn', KNeighborsClassifier())], voting='soft')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3f6b7d-7e99-4c02-955f-7aa1d65722b2",
   "metadata": {},
   "source": [
    "### Evaluating Models with 10-Fold Cross-Validation\n",
    "\n",
    "We will use 10-fold cross-validation to evaluate each classifier, storing the F1-scores for each fold iteration. We'll store these scores to calculate the average and standard deviation of F1-scores later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c63d89-3b6c-4458-be5a-91a4a49591d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cross-validation and F1 scorer\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "f1_scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "# Function to evaluate a model with cross-validation\n",
    "def evaluate_model(model, X, y, kf):\n",
    "    f1_scores = cross_val_score(model, X, y, cv=kf, scoring=f1_scorer)\n",
    "    return f1_scores\n",
    "\n",
    "# Dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Evaluate individual classifiers\n",
    "for name, clf in classifiers.items():\n",
    "    f1_scores = evaluate_model(clf, X, y, kf)\n",
    "    results[name] = f1_scores\n",
    "\n",
    "# Evaluate ensemble classifiers\n",
    "for name, clf in ensemble_classifiers.items():\n",
    "    f1_scores = evaluate_model(clf, X, y, kf)\n",
    "    results[name] = f1_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38555578-7051-4d74-8388-e84f422c81a2",
   "metadata": {},
   "source": [
    "### Reporting Global Results\n",
    "\n",
    "For each model, we will calculate and display the mean and standard deviation of the F1-scores across the 10 folds. This will give us a sense of the overall performance and consistency of each classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fb27c9-3e60-473f-bc7a-cd389628b93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print average F1-score and standard deviation for each classifier\n",
    "for name, f1_scores in results.items():\n",
    "    print(f\"{name}: Mean F1-score = {np.mean(f1_scores):.3f}, Standard Deviation = {np.std(f1_scores):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecfad16-04d7-4bb3-bf5d-80f46f7e8954",
   "metadata": {},
   "source": [
    "### Visualizing the Results with a Boxplot and Mean Markers\n",
    "\n",
    "We will use a boxplot to visualize the distribution of F1-scores for each model across the 10 folds. Additionally, we will display the mean F1-score for each model using a point marker on the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b3d92a-f1d9-46ca-bf87-bc5303b9247d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results to a DataFrame for easier plotting\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Create the boxplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.boxplot(data=results_df)  # Boxplot\n",
    "\n",
    "# Compute mean F1-score for each model\n",
    "mean_f1_scores = results_df.mean()\n",
    "\n",
    "# Plot the mean F1-score for each model with a red marker\n",
    "for i in range(len(mean_f1_scores)):\n",
    "    # x-coordinate is the position of the category (i), y-coordinate is the mean F1-score\n",
    "    plt.scatter(i, mean_f1_scores[i], color='red', marker='o', s=10, zorder=3, label='Mean F1-score' if i == 0 else \"\")\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('F1-scores of Classification Models with Mean Markers')\n",
    "plt.ylabel('F1-score')\n",
    "plt.xticks(ticks=np.arange(len(results_df.columns)), labels=results_df.columns, rotation=45)\n",
    "\n",
    "# Only show the legend once\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d20c93-fe42-4f08-8ae2-3088cd29af7d",
   "metadata": {},
   "source": [
    "### Displaying the Confusion Matrix for the Best Models\n",
    "\n",
    "We will now display the confusion matrices for the best-performing model from the base classifiers and the best-performing model from the ensemble classifiers, based on their mean F1-scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22a5fad-b182-4fa0-8f75-881e3c8c65de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Get the best base classifier and best ensemble classifier based on mean F1-scores\n",
    "best_base_model_name = results_df[classifiers.keys()].mean().idxmax()\n",
    "best_ensemble_model_name = results_df[ensemble_classifiers.keys()].mean().idxmax()\n",
    "\n",
    "best_base_model = classifiers[best_base_model_name]\n",
    "best_ensemble_model = ensemble_classifiers[best_ensemble_model_name]\n",
    "\n",
    "# Train the best base model and best ensemble model on the entire dataset\n",
    "best_base_model.fit(X, y)\n",
    "best_ensemble_model.fit(X, y)\n",
    "\n",
    "# Predict using the trained models\n",
    "y_pred_base = best_base_model.predict(X)\n",
    "y_pred_ensemble = best_ensemble_model.predict(X)\n",
    "\n",
    "# Generate confusion matrices\n",
    "conf_matrix_base = confusion_matrix(y, y_pred_base)\n",
    "conf_matrix_ensemble = confusion_matrix(y, y_pred_ensemble)\n",
    "\n",
    "# Display confusion matrix for the best base model\n",
    "print(f\"Confusion Matrix for the best base model ({best_base_model_name}):\")\n",
    "ConfusionMatrixDisplay(confusion_matrix=conf_matrix_base, display_labels=iris.target_names).plot()\n",
    "plt.title(f\"Confusion Matrix - {best_base_model_name}\")\n",
    "plt.show()\n",
    "\n",
    "# Display confusion matrix for the best ensemble model\n",
    "print(f\"Confusion Matrix for the best ensemble model ({best_ensemble_model_name}):\")\n",
    "ConfusionMatrixDisplay(confusion_matrix=conf_matrix_ensemble, display_labels=iris.target_names).plot()\n",
    "plt.title(f\"Confusion Matrix - {best_ensemble_model_name}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0cc8d1-307e-4d33-bb2c-b7255387cc59",
   "metadata": {},
   "source": [
    "## Unbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee691daf-fbf7-41e8-bd87-e69a6edb254a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, StackingClassifier, VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load the Credit Card Fraud dataset (downloaded locally or from Kaggle)\n",
    "data = pd.read_csv('creditcard.csv')\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop(columns=['Class'])\n",
    "y = data['Class']\n",
    "\n",
    "# Define base classifiers\n",
    "classifiers = {\n",
    "    'CART': DecisionTreeClassifier(),\n",
    "    'GNB': GaussianNB(),\n",
    "    'kNN': KNeighborsClassifier(),\n",
    "    'SVM': SVC()\n",
    "}\n",
    "\n",
    "# Define ensemble classifiers\n",
    "ensemble_classifiers = {\n",
    "    'Bagging': BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42),\n",
    "    'Boosting': AdaBoostClassifier(estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42),\n",
    "    'Stacking': StackingClassifier(estimators=[('dt', DecisionTreeClassifier()), ('svc', SVC(probability=True))], final_estimator=RandomForestClassifier(), cv=5),\n",
    "    'Voting': VotingClassifier(estimators=[('dt', DecisionTreeClassifier()), ('svc', SVC())], voting='hard')\n",
    "}\n",
    "\n",
    "# Combine classifiers into one dictionary for easier iteration\n",
    "all_classifiers = {**classifiers, **ensemble_classifiers}\n",
    "\n",
    "# Store the F1-scores for each model and fold\n",
    "results = {name: [] for name in all_classifiers.keys()}\n",
    "\n",
    "# 10-fold cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation for each classifier\n",
    "for name, model in all_classifiers.items():\n",
    "    for train_idx, test_idx in cv.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        \n",
    "        # Train and predict\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Store F1-score\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        results[name].append(f1)\n",
    "\n",
    "# Convert results to a DataFrame for easier plotting\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Plot a boxplot to visualize the distribution of F1-scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.boxplot(data=results_df)\n",
    "\n",
    "# Plot mean F1-score for each model with markers\n",
    "mean_f1_scores = results_df.mean()\n",
    "for i, mean in enumerate(mean_f1_scores):\n",
    "    plt.scatter(i, mean, color='red', marker='o', s=10, zorder=3, label='Mean F1-score' if i == 0 else \"\")\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('F1-scores of Classification Models (Credit Card Fraud Dataset)')\n",
    "plt.ylabel('F1-score')\n",
    "plt.xticks(ticks=np.arange(len(results_df.columns)), labels=results_df.columns, rotation=45)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Get the best base classifier and best ensemble classifier based on mean F1-scores\n",
    "best_base_model_name = results_df[classifiers.keys()].mean().idxmax()\n",
    "best_ensemble_model_name = results_df[ensemble_classifiers.keys()].mean().idxmax()\n",
    "\n",
    "best_base_model = classifiers[best_base_model_name]\n",
    "best_ensemble_model = ensemble_classifiers[best_ensemble_model_name]\n",
    "\n",
    "# Train the best base model and best ensemble model on the entire dataset\n",
    "best_base_model.fit(X, y)\n",
    "best_ensemble_model.fit(X, y)\n",
    "\n",
    "# Predict using the trained models\n",
    "y_pred_base = best_base_model.predict(X)\n",
    "y_pred_ensemble = best_ensemble_model.predict(X)\n",
    "\n",
    "# Generate confusion matrices\n",
    "conf_matrix_base = confusion_matrix(y, y_pred_base)\n",
    "conf_matrix_ensemble = confusion_matrix(y, y_pred_ensemble)\n",
    "\n",
    "# Display confusion matrix for the best base model\n",
    "print(f\"Confusion Matrix for the best base model ({best_base_model_name}):\")\n",
    "ConfusionMatrixDisplay(confusion_matrix=conf_matrix_base, display_labels=['No Fraud', 'Fraud']).plot()\n",
    "plt.title(f\"Confusion Matrix - {best_base_model_name}\")\n",
    "plt.show()\n",
    "\n",
    "# Display confusion matrix for the best ensemble model\n",
    "print(f\"Confusion Matrix for the best ensemble model ({best_ensemble_model_name}):\")\n",
    "ConfusionMatrixDisplay(confusion_matrix=conf_matrix_ensemble, display_labels=['No Fraud', 'Fraud']).plot()\n",
    "plt.title(f\"Confusion Matrix - {best_ensemble_model_name}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddb4e76-be90-4d4a-8a1d-bfa586b639cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
