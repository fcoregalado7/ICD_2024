{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d98e2db-8519-4cd8-9f75-9e65331585a1",
   "metadata": {},
   "source": [
    "# Notebook ICD - 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2bea34-06dd-4b57-90da-dce66eeedabf",
   "metadata": {},
   "source": [
    "Install libraries via terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "582ef0ff-9295-4337-89ee-764fe81c0f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /opt/anaconda3/lib/python3.10/site-packages (3.7.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/anaconda3/lib/python3.10/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.10/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/anaconda3/lib/python3.10/site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/anaconda3/lib/python3.10/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/anaconda3/lib/python3.10/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/anaconda3/lib/python3.10/site-packages (from spacy) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/anaconda3/lib/python3.10/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/anaconda3/lib/python3.10/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/anaconda3/lib/python3.10/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/anaconda3/lib/python3.10/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/anaconda3/lib/python3.10/site-packages (from spacy) (0.12.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/anaconda3/lib/python3.10/site-packages (from spacy) (4.66.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.10/site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/anaconda3/lib/python3.10/site-packages (from spacy) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.10/site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.10/site-packages (from spacy) (72.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.10/site-packages (from spacy) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/anaconda3/lib/python3.10/site-packages (from spacy) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/anaconda3/lib/python3.10/site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/anaconda3/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/anaconda3/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/anaconda3/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/anaconda3/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/anaconda3/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/anaconda3/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/anaconda3/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/anaconda3/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/anaconda3/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.19.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/anaconda3/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.10/site-packages (from jinja2->spacy) (2.1.3)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /opt/anaconda3/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.0)\n",
      "Requirement already satisfied: nltk in /opt/anaconda3/lib/python3.10/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.10/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/lib/python3.10/site-packages (from nltk) (2024.7.24)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.10/site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.10/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/anaconda3/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/lib/python3.10/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "!pip install nltk\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476a1956-9666-48c5-98a5-2cbb514c22ef",
   "metadata": {},
   "source": [
    "Importing necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ce4c060-b967-4856-b7cf-b6ea32740ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy as spc\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04d0bc4-caab-43b2-b791-7a903f2a67f6",
   "metadata": {},
   "source": [
    "## Datos de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73f38d8f-f3e8-4bae-8afe-b74fd140ae4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Mar18blink Estoy buscando un producto genial por menos de 50. He encontrado muchos en https://t.co/FI1ShlDozc. ¿Qué opinas? Quiero comprarlo ya!!!\n"
     ]
    }
   ],
   "source": [
    "oracion = \"@Mar18blink Estoy buscando un producto genial por menos de 50. He encontrado muchos en https://t.co/FI1ShlDozc. ¿Qué opinas? Quiero comprarlo ya!!!\"\n",
    "print(oracion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ace6213-b9e5-4dde-80f8-cffede8fc3b7",
   "metadata": {},
   "source": [
    "## Procesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72533121-a276-4248-9cd1-71bfdc4ce66f",
   "metadata": {},
   "source": [
    "### Limpieza de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2afad44f-9233-4584-9e43-5cad07ef213e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " estoy buscando un producto genial por menos de  he encontrado muchos en  qué opinas quiero comprarlo ya\n"
     ]
    }
   ],
   "source": [
    "oracion = oracion.lower()\n",
    "oracion = re.sub(r\"@\\S+\", \"\", oracion)  # Eliminar menciones a usuarios\n",
    "oracion = re.sub(\"http[s]?\\://\\S+\", \"\", oracion)  # Eliminar enlaces\n",
    "oracion = re.sub(r\"#\\S+\", \"\", oracion)  # Eliminar hashtags\n",
    "oracion = re.sub(r\"[0-9]\", \"\", oracion)  # Eliminar números\n",
    "oracion = re.sub(r\"(\\(.*\\))|(\\[.*\\])\", \"\", oracion)  # Eliminar paréntesis y corchetes\n",
    "oracion = re.sub(r\"\\n\", \"\", oracion)  # Eliminar caracteres de nueva línea\n",
    "oracion = re.sub(r\"(http[s]?\\://\\S+)|([\\[\\(].*[\\)\\]])|([#@]\\S+)|\\n\", \"\", oracion)  # Eliminar varios patrones\n",
    "oracion = re.sub(r\"(\\.)|(,)\", \"\", oracion)  # Eliminar puntos y comas\n",
    "oracion = re.sub(r\"[¡!]\", \"\", oracion)  # Eliminar signos de admiración \n",
    "oracion = re.sub(r\"[¿?]\", \"\", oracion)  # Eliminar signos de exclamación\n",
    "print(oracion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbb2c8a6-ba40-4844-860b-15d8b3131706",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/paco/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.data.path.append('/Users/paco/nltk_data')  # Para asegurarte de que NLTK busque en el directorio correcto\n",
    "nltk.download('punkt', force=True)  # Vuelve a descargar el paquete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a3a8db5-1a85-4502-ac90-16a1b8699ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/paco/nltk_data/tokenizers/punkt/english.pickle\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(nltk.data.find('tokenizers/punkt/english.pickle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da20449-7603-4d01-9866-6be0fbf0063c",
   "metadata": {},
   "source": [
    "### Tokenización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f09a8ada-c4a9-4b32-8b01-8dffb962255e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /Users/paco/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86a798d9-a52d-41bf-80b6-4d36808cee15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['estoy', 'buscando', 'un', 'producto', 'genial', 'por', 'menos', 'de', 'he', 'encontrado', 'muchos', 'en', 'qué', 'opinas', 'quiero', 'comprarlo', 'ya']\n"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(oracion, language='spanish')\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba33108d-855f-4898-a16d-82d8fd19ee4f",
   "metadata": {},
   "source": [
    "### Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a9990057-f614-463c-bc59-276163f9c16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: unknown sort specifier\n",
      "['buscando', 'producto', 'genial', 'menos', 'encontrado', 'opinas', 'quiero', 'comprarlo']\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "spanish_stopwords = stopwords.words('spanish')\n",
    "palabras_filtradas = [palabra for palabra in tokens if palabra not in spanish_stopwords]\n",
    "print(palabras_filtradas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd83dce-3bb0-4258-a752-3297c1fffa55",
   "metadata": {},
   "source": [
    "### Lematización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9854623a-2f73-46ec-8f1d-8cd14e31d670",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4135930192.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[35], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    sudo python3 -m spacy download es\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "sudo python3 -m spacy download es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8a78c030-5094-48a0-aa9c-dc63ff9bfddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buscar producto genial menos encontrado opina querer comprar él\n"
     ]
    }
   ],
   "source": [
    "nlp = spc.load(\"es_core_news_sm\")\n",
    "lema = nlp(\" \".join(palabras_filtradas))\n",
    "oracion_lematizada = \" \".join([token.lemma_ for token in lema])\n",
    "print(oracion_lematizada)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115d08ba-3bff-4982-8a0d-53e1b16209f4",
   "metadata": {},
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2736fdd5-dde2-48d7-ad8d-01d1db87f66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizador = CountVectorizer()\n",
    "vectores = vectorizador.fit_transform([oracion_lematizada])\n",
    "vocabulario = vectorizador.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c90384-68b0-460a-8cd3-82becb828de8",
   "metadata": {},
   "source": [
    "### Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c71ef6ab-76b1-4e20-adbb-5dd1c25e1348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oración de entrada:  estoy buscando un producto genial por menos de  he encontrado muchos en  qué opinas quiero comprarlo ya\n",
      "Oración lematizada: buscar producto genial menos encontrado opina querer comprar él\n",
      "Vectores Bag of Words: [[1 1 1 1 1 1 1 1 1]]\n",
      "Vocabulario: ['buscar' 'comprar' 'encontrado' 'genial' 'menos' 'opina' 'producto'\n",
      " 'querer' 'él']\n"
     ]
    }
   ],
   "source": [
    "print(\"Oración de entrada:\", oracion)\n",
    "print(\"Oración lematizada:\", oracion_lematizada)\n",
    "print(\"Vectores Bag of Words:\", vectores.toarray())\n",
    "print(\"Vocabulario:\", vocabulario)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248b9bcd-1d1c-443b-b06a-8551bdee0af7",
   "metadata": {},
   "source": [
    "### Construir Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0c552894-bc08-4397-8982-3cb8df82052d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buscar</th>\n",
       "      <th>comprar</th>\n",
       "      <th>encontrado</th>\n",
       "      <th>genial</th>\n",
       "      <th>menos</th>\n",
       "      <th>opina</th>\n",
       "      <th>producto</th>\n",
       "      <th>querer</th>\n",
       "      <th>él</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   buscar  comprar  encontrado  genial  menos  opina  producto  querer  él\n",
       "0       1        1           1       1      1      1         1       1   1"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bw = pd.DataFrame.sparse.from_spmatrix(vectores,columns = vocabulario)\n",
    "df_bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae042ce-df3f-4b1e-8f6d-306c9c621703",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
