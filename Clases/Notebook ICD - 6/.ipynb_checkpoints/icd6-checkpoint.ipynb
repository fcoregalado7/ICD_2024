{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31b49452-9728-40aa-ae72-e1e57c785c96",
   "metadata": {
    "id": "31b49452-9728-40aa-ae72-e1e57c785c96"
   },
   "source": [
    "# Notebook ICD - 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1603026a-a4f8-4713-bbd7-21f6363fa4e4",
   "metadata": {
    "id": "1603026a-a4f8-4713-bbd7-21f6363fa4e4"
   },
   "source": [
    "Install libreries via terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23792d0e-9b5c-4a92-aead-2e25b2bf7d81",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "23792d0e-9b5c-4a92-aead-2e25b2bf7d81",
    "outputId": "a836049c-8740-4df6-b28f-8aca6fde7b47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading keras-3.5.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting absl-py (from keras)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.10/site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.10/site-packages (from keras) (13.7.1)\n",
      "Collecting namex (from keras)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Requirement already satisfied: h5py in /opt/anaconda3/lib/python3.10/site-packages (from keras) (3.11.0)\n",
      "Collecting optree (from keras)\n",
      "  Downloading optree-0.12.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (47 kB)\n",
      "Collecting ml-dtypes (from keras)\n",
      "  Downloading ml_dtypes-0.4.0-cp310-cp310-macosx_10_9_universal2.whl.metadata (20 kB)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.10/site-packages (from keras) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/anaconda3/lib/python3.10/site-packages (from optree->keras) (4.11.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/lib/python3.10/site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.10/site-packages (from rich->keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.0)\n",
      "Downloading keras-3.5.0-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading ml_dtypes-0.4.0-cp310-cp310-macosx_10_9_universal2.whl (390 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.12.1-cp310-cp310-macosx_11_0_arm64.whl (282 kB)\n",
      "Installing collected packages: namex, optree, ml-dtypes, absl-py, keras\n",
      "Successfully installed absl-py-2.1.0 keras-3.5.0 ml-dtypes-0.4.0 namex-0.0.8 optree-0.12.1\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.17.0-cp310-cp310-macosx_12_0_arm64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/anaconda3/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /opt/anaconda3/lib/python3.10/site-packages (from tensorflow) (3.11.0)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /opt/anaconda3/lib/python3.10/site-packages (from tensorflow) (0.4.0)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.10/site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/anaconda3/lib/python3.10/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.10/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.10/site-packages (from tensorflow) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/lib/python3.10/site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/lib/python3.10/site-packages (from tensorflow) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.66.1-cp310-cp310-macosx_12_0_universal2.whl.metadata (3.9 kB)\n",
      "Collecting tensorboard<2.18,>=2.17 (from tensorflow)\n",
      "  Downloading tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: keras>=3.2.0 in /opt/anaconda3/lib/python3.10/site-packages (from tensorflow) (3.5.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-macosx_12_0_arm64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/anaconda3/lib/python3.10/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in /opt/anaconda3/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /opt/anaconda3/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.18,>=2.17->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/lib/python3.10/site-packages (from rich->keras>=3.2.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.10/site-packages (from rich->keras>=3.2.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.0)\n",
      "Downloading tensorflow-2.17.0-cp310-cp310-macosx_12_0_arm64.whl (236.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.1/236.1 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.66.1-cp310-cp310-macosx_12_0_universal2.whl (10.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.6/10.6 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl (25.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.8/25.8 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Downloading tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-macosx_12_0_arm64.whl (3.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Installing collected packages: libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, opt-einsum, grpcio, google-pasta, gast, astunparse, tensorboard, tensorflow\n",
      "Successfully installed astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.66.1 libclang-18.1.1 opt-einsum-3.3.0 tensorboard-2.17.1 tensorboard-data-server-0.7.2 tensorflow-2.17.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-2.4.0\n",
      "Collecting Augmentor\n",
      "  Downloading Augmentor-0.2.12-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: Pillow>=5.2.0 in /opt/anaconda3/lib/python3.10/site-packages (from Augmentor) (10.4.0)\n",
      "Requirement already satisfied: tqdm>=4.9.0 in /opt/anaconda3/lib/python3.10/site-packages (from Augmentor) (4.66.5)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /opt/anaconda3/lib/python3.10/site-packages (from Augmentor) (1.26.4)\n",
      "Downloading Augmentor-0.2.12-py2.py3-none-any.whl (38 kB)\n",
      "Installing collected packages: Augmentor\n",
      "Successfully installed Augmentor-0.2.12\n",
      "Collecting tensorflow-io\n",
      "  Downloading tensorflow_io-0.37.1-cp310-cp310-macosx_12_0_arm64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.37.1 in /opt/anaconda3/lib/python3.10/site-packages (from tensorflow-io) (0.37.1)\n",
      "Downloading tensorflow_io-0.37.1-cp310-cp310-macosx_12_0_arm64.whl (31.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.8/31.8 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tensorflow-io\n",
      "Successfully installed tensorflow-io-0.37.1\n",
      "Requirement already satisfied: IPython in /opt/anaconda3/lib/python3.10/site-packages (8.25.0)\n",
      "Requirement already satisfied: decorator in /opt/anaconda3/lib/python3.10/site-packages (from IPython) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/anaconda3/lib/python3.10/site-packages (from IPython) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/anaconda3/lib/python3.10/site-packages (from IPython) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/anaconda3/lib/python3.10/site-packages (from IPython) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/anaconda3/lib/python3.10/site-packages (from IPython) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /opt/anaconda3/lib/python3.10/site-packages (from IPython) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /opt/anaconda3/lib/python3.10/site-packages (from IPython) (5.14.3)\n",
      "Requirement already satisfied: exceptiongroup in /opt/anaconda3/lib/python3.10/site-packages (from IPython) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in /opt/anaconda3/lib/python3.10/site-packages (from IPython) (4.11.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/anaconda3/lib/python3.10/site-packages (from IPython) (4.8.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/anaconda3/lib/python3.10/site-packages (from jedi>=0.16->IPython) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/anaconda3/lib/python3.10/site-packages (from pexpect>4.3->IPython) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/anaconda3/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->IPython) (0.2.5)\n",
      "Requirement already satisfied: executing in /opt/anaconda3/lib/python3.10/site-packages (from stack-data->IPython) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /opt/anaconda3/lib/python3.10/site-packages (from stack-data->IPython) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /opt/anaconda3/lib/python3.10/site-packages (from stack-data->IPython) (0.2.2)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.10/site-packages (from asttokens->stack-data->IPython) (1.16.0)\n",
      "Collecting textattack\n",
      "  Downloading textattack-0.3.10-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting bert-score>=0.3.5 (from textattack)\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting editdistance (from textattack)\n",
      "  Downloading editdistance-0.8.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (3.9 kB)\n",
      "Collecting flair (from textattack)\n",
      "  Downloading flair-0.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.10/site-packages (from textattack) (3.13.1)\n",
      "Collecting language-tool-python (from textattack)\n",
      "  Downloading language_tool_python-2.8.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting lemminflect (from textattack)\n",
      "  Downloading lemminflect-0.2.3-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting lru-dict (from textattack)\n",
      "  Downloading lru_dict-1.3.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (4.5 kB)\n",
      "Collecting datasets>=2.4.0 (from textattack)\n",
      "  Downloading datasets-3.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: nltk in /opt/anaconda3/lib/python3.10/site-packages (from textattack) (3.9.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/anaconda3/lib/python3.10/site-packages (from textattack) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /opt/anaconda3/lib/python3.10/site-packages (from textattack) (2.2.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/anaconda3/lib/python3.10/site-packages (from textattack) (1.13.1)\n",
      "Collecting torch!=1.8,>=1.7.0 (from textattack)\n",
      "  Downloading torch-2.4.1-cp310-none-macosx_11_0_arm64.whl.metadata (26 kB)\n",
      "Collecting transformers>=4.30.0 (from textattack)\n",
      "  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting terminaltables (from textattack)\n",
      "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.10/site-packages (from textattack) (4.66.5)\n",
      "Collecting word2number (from textattack)\n",
      "  Downloading word2number-1.1.zip (9.7 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting num2words (from textattack)\n",
      "  Downloading num2words-0.5.13-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: more-itertools in /opt/anaconda3/lib/python3.10/site-packages (from textattack) (10.1.0)\n",
      "Collecting pinyin>=0.4.0 (from textattack)\n",
      "  Downloading pinyin-0.4.0.tar.gz (3.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting jieba (from textattack)\n",
      "  Downloading jieba-0.42.1.tar.gz (19.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting OpenHowNet (from textattack)\n",
      "  Downloading OpenHowNet-2.0-py3-none-any.whl.metadata (821 bytes)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.10/site-packages (from bert-score>=0.3.5->textattack) (2.32.3)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.10/site-packages (from bert-score>=0.3.5->textattack) (3.9.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/anaconda3/lib/python3.10/site-packages (from bert-score>=0.3.5->textattack) (24.1)\n",
      "Collecting pyarrow>=15.0.0 (from datasets>=2.4.0->textattack)\n",
      "  Downloading pyarrow-17.0.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/lib/python3.10/site-packages (from datasets>=2.4.0->textattack) (0.3.8)\n",
      "Collecting xxhash (from datasets>=2.4.0->textattack)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets>=2.4.0->textattack)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/anaconda3/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets>=2.4.0->textattack) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/lib/python3.10/site-packages (from datasets>=2.4.0->textattack) (3.9.5)\n",
      "Collecting huggingface-hub>=0.22.0 (from datasets>=2.4.0->textattack)\n",
      "  Downloading huggingface_hub-0.24.6-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.10/site-packages (from datasets>=2.4.0->textattack) (6.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.10/site-packages (from pandas>=1.0.1->textattack) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.10/site-packages (from pandas>=1.0.1->textattack) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.10/site-packages (from pandas>=1.0.1->textattack) (2023.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.10/site-packages (from torch!=1.8,>=1.7.0->textattack) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.10/site-packages (from torch!=1.8,>=1.7.0->textattack) (1.13.2)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.10/site-packages (from torch!=1.8,>=1.7.0->textattack) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.10/site-packages (from torch!=1.8,>=1.7.0->textattack) (3.1.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.10/site-packages (from transformers>=4.30.0->textattack) (2024.7.24)\n",
      "Collecting safetensors>=0.4.1 (from transformers>=4.30.0->textattack)\n",
      "  Downloading safetensors-0.4.5-cp310-cp310-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers>=4.30.0->textattack)\n",
      "  Downloading tokenizers-0.19.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: boto3>=1.20.27 in /opt/anaconda3/lib/python3.10/site-packages (from flair->textattack) (1.34.69)\n",
      "Collecting conllu<5.0.0,>=4.0 (from flair->textattack)\n",
      "  Downloading conllu-4.5.3-py2.py3-none-any.whl.metadata (19 kB)\n",
      "Collecting deprecated>=1.2.13 (from flair->textattack)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting ftfy>=6.1.0 (from flair->textattack)\n",
      "  Downloading ftfy-6.2.3-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting gdown>=4.4.0 (from flair->textattack)\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langdetect>=1.0.9 (from flair->textattack)\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: lxml>=4.8.0 in /opt/anaconda3/lib/python3.10/site-packages (from flair->textattack) (5.2.1)\n",
      "Collecting mpld3>=0.3 (from flair->textattack)\n",
      "  Downloading mpld3-0.5.10-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting pptree>=3.1 (from flair->textattack)\n",
      "  Downloading pptree-3.1.tar.gz (3.0 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pytorch-revgrad>=0.2.0 (from flair->textattack)\n",
      "  Downloading pytorch_revgrad-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /opt/anaconda3/lib/python3.10/site-packages (from flair->textattack) (1.5.1)\n",
      "Collecting segtok>=1.5.11 (from flair->textattack)\n",
      "  Downloading segtok-1.5.11-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting sqlitedict>=2.0.0 (from flair->textattack)\n",
      "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tabulate>=0.8.10 in /opt/anaconda3/lib/python3.10/site-packages (from flair->textattack) (0.9.0)\n",
      "Collecting transformer-smaller-training-vocab>=0.2.3 (from flair->textattack)\n",
      "  Downloading transformer_smaller_training_vocab-0.4.0-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting wikipedia-api>=0.5.7 (from flair->textattack)\n",
      "  Downloading wikipedia_api-0.7.1.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: semver<4.0.0,>=3.0.0 in /opt/anaconda3/lib/python3.10/site-packages (from flair->textattack) (3.0.2)\n",
      "Collecting bioc<3.0.0,>=2.0.0 (from flair->textattack)\n",
      "  Downloading bioc-2.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: pip in /opt/anaconda3/lib/python3.10/site-packages (from language-tool-python->textattack) (24.2)\n",
      "Requirement already satisfied: wheel in /opt/anaconda3/lib/python3.10/site-packages (from language-tool-python->textattack) (0.43.0)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.10/site-packages (from nltk->textattack) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.10/site-packages (from nltk->textattack) (1.4.2)\n",
      "Collecting docopt>=0.6.2 (from num2words->textattack)\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting anytree (from OpenHowNet->textattack)\n",
      "  Downloading anytree-2.12.1-py3-none-any.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.10/site-packages (from OpenHowNet->textattack) (72.1.0)\n",
      "Collecting jsonlines>=1.2.0 (from bioc<3.0.0,>=2.0.0->flair->textattack)\n",
      "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting intervaltree (from bioc<3.0.0,>=2.0.0->flair->textattack)\n",
      "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: botocore<1.35.0,>=1.34.69 in /opt/anaconda3/lib/python3.10/site-packages (from boto3>=1.20.27->flair->textattack) (1.34.69)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/anaconda3/lib/python3.10/site-packages (from boto3>=1.20.27->flair->textattack) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/anaconda3/lib/python3.10/site-packages (from boto3>=1.20.27->flair->textattack) (0.10.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/anaconda3/lib/python3.10/site-packages (from deprecated>=1.2.13->flair->textattack) (1.14.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets>=2.4.0->textattack) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets>=2.4.0->textattack) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets>=2.4.0->textattack) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets>=2.4.0->textattack) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets>=2.4.0->textattack) (1.9.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets>=2.4.0->textattack) (4.0.3)\n",
      "Collecting wcwidth<0.3.0,>=0.2.12 (from ftfy>=6.1.0->flair->textattack)\n",
      "  Using cached wcwidth-0.2.13-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.10/site-packages (from gdown>=4.4.0->flair->textattack) (4.12.3)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.10/site-packages (from langdetect>=1.0.9->flair->textattack) (1.16.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.10/site-packages (from matplotlib->bert-score>=0.3.5->textattack) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.10/site-packages (from matplotlib->bert-score>=0.3.5->textattack) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.10/site-packages (from matplotlib->bert-score>=0.3.5->textattack) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.10/site-packages (from matplotlib->bert-score>=0.3.5->textattack) (1.4.4)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.10/site-packages (from matplotlib->bert-score>=0.3.5->textattack) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.10/site-packages (from matplotlib->bert-score>=0.3.5->textattack) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.10/site-packages (from requests->bert-score>=0.3.5->textattack) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.10/site-packages (from requests->bert-score>=0.3.5->textattack) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.10/site-packages (from requests->bert-score>=0.3.5->textattack) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.10/site-packages (from requests->bert-score>=0.3.5->textattack) (2024.7.4)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.10/site-packages (from scikit-learn>=1.0.2->flair->textattack) (3.5.0)\n",
      "Requirement already satisfied: protobuf in /opt/anaconda3/lib/python3.10/site-packages (from transformers[sentencepiece]<5.0.0,>=4.18.0->flair->textattack) (3.20.3)\n",
      "Collecting sentencepiece!=0.1.92,>=0.1.91 (from transformers[sentencepiece]<5.0.0,>=4.18.0->flair->textattack)\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.10/site-packages (from jinja2->torch!=1.8,>=1.7.0->textattack) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.10/site-packages (from sympy->torch!=1.8,>=1.7.0->textattack) (1.3.0)\n",
      "Collecting accelerate>=0.21.0 (from transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair->textattack)\n",
      "  Downloading accelerate-0.34.2-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.10/site-packages (from beautifulsoup4->gdown>=4.4.0->flair->textattack) (2.5)\n",
      "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /opt/anaconda3/lib/python3.10/site-packages (from intervaltree->bioc<3.0.0,>=2.0.0->flair->textattack) (2.4.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/anaconda3/lib/python3.10/site-packages (from requests[socks]->gdown>=4.4.0->flair->textattack) (1.7.1)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/lib/python3.10/site-packages (from accelerate>=0.21.0->transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair->textattack) (5.9.0)\n",
      "Downloading textattack-0.3.10-py3-none-any.whl (445 kB)\n",
      "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "Downloading datasets-3.0.0-py3-none-any.whl (474 kB)\n",
      "Downloading torch-2.4.1-cp310-none-macosx_11_0_arm64.whl (62.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading editdistance-0.8.1-cp310-cp310-macosx_11_0_arm64.whl (79 kB)\n",
      "Downloading flair-0.14.0-py3-none-any.whl (776 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.5/776.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading language_tool_python-2.8.1-py3-none-any.whl (35 kB)\n",
      "Downloading lemminflect-0.2.3-py3-none-any.whl (769 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m769.7/769.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lru_dict-1.3.0-cp310-cp310-macosx_11_0_arm64.whl (11 kB)\n",
      "Downloading num2words-0.5.13-py3-none-any.whl (143 kB)\n",
      "Downloading OpenHowNet-2.0-py3-none-any.whl (18 kB)\n",
      "Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
      "Downloading bioc-2.1-py3-none-any.whl (33 kB)\n",
      "Downloading conllu-4.5.3-py2.py3-none-any.whl (16 kB)\n",
      "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading ftfy-6.2.3-py3-none-any.whl (43 kB)\n",
      "Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Downloading huggingface_hub-0.24.6-py3-none-any.whl (417 kB)\n",
      "Downloading mpld3-0.5.10-py3-none-any.whl (202 kB)\n",
      "Downloading pyarrow-17.0.0-cp310-cp310-macosx_11_0_arm64.whl (27.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.2/27.2 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytorch_revgrad-0.2.0-py3-none-any.whl (4.6 kB)\n",
      "Downloading safetensors-0.4.5-cp310-cp310-macosx_11_0_arm64.whl (381 kB)\n",
      "Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
      "Downloading tokenizers-0.19.1-cp310-cp310-macosx_11_0_arm64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformer_smaller_training_vocab-0.4.0-py3-none-any.whl (14 kB)\n",
      "Downloading anytree-2.12.1-py3-none-any.whl (44 kB)\n",
      "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Downloading xxhash-3.5.0-cp310-cp310-macosx_11_0_arm64.whl (30 kB)\n",
      "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
      "Downloading sentencepiece-0.2.0-cp310-cp310-macosx_11_0_arm64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
      "Downloading accelerate-0.34.2-py3-none-any.whl (324 kB)\n",
      "Building wheels for collected packages: pinyin, jieba, word2number, docopt, langdetect, pptree, sqlitedict, wikipedia-api, intervaltree\n",
      "  Building wheel for pinyin (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pinyin: filename=pinyin-0.4.0-py3-none-any.whl size=3630477 sha256=176814ae28906dae9263386775b6c4b3b7175b4760dbf51aeb7fab7a5abb3b29\n",
      "  Stored in directory: /Users/paco/Library/Caches/pip/wheels/33/38/af/616fc6f154aa5bae65a1da12b22d79943434269f0468ff9b3f\n",
      "  Building wheel for jieba (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314458 sha256=6e3212fb0fde849755c5bfb3b3add7faa544fe69caceb68ad1e61040a0efb6e7\n",
      "  Stored in directory: /Users/paco/Library/Caches/pip/wheels/c9/69/31/d56d90b22a1777b0b231e234b00302a55be255930f8bd92dcd\n",
      "  Building wheel for word2number (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5569 sha256=eb359aaf5a5373d60e4edcb78426cb6e1e960e4e89d6b1600ef5099a4f46d1ef\n",
      "  Stored in directory: /Users/paco/Library/Caches/pip/wheels/84/ff/26/d3cfbd971e96c5aa3737ecfced81628830d7359b55fbb8ca3b\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13705 sha256=adbf5bf2b2e20a2907ae4563a2efd3d5482dd67eb855a189acc0e14725ce7598\n",
      "  Stored in directory: /Users/paco/Library/Caches/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993222 sha256=99185fc6871843db9f0e9bec1b19ed8a7c59b44bc041b8b6b225c26ed38c58ba\n",
      "  Stored in directory: /Users/paco/Library/Caches/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
      "  Building wheel for pptree (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4608 sha256=66acf9faf97e7eb11efbd4ee197b983ddb9189fe50662cb39904a932d190dbe1\n",
      "  Stored in directory: /Users/paco/Library/Caches/pip/wheels/9f/b6/0e/6f26eb9e6eb53ff2107a7888d72b5a6a597593956113037828\n",
      "  Building wheel for sqlitedict (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16863 sha256=d3a11eda20cff4f4422db8c463a563907d4a08a6d609a903d46ee1ad4e4f9e22\n",
      "  Stored in directory: /Users/paco/Library/Caches/pip/wheels/79/d6/e7/304e0e6cb2221022c26d8161f7c23cd4f259a9e41e8bbcfabd\n",
      "  Building wheel for wikipedia-api (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wikipedia-api: filename=Wikipedia_API-0.7.1-py3-none-any.whl size=14346 sha256=ab05513b384325fe610500a26192475c9d1e4cd344cef067cc3b8259cf93d982\n",
      "  Stored in directory: /Users/paco/Library/Caches/pip/wheels/4c/96/18/b9201cc3e8b47b02b510460210cfd832ccf10c0c4dd0522962\n",
      "  Building wheel for intervaltree (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26095 sha256=17724abd95ce6baf7888b8461c30bc71b8307ffae237e6b40482e0947ae762d0\n",
      "  Stored in directory: /Users/paco/Library/Caches/pip/wheels/fa/80/8c/43488a924a046b733b64de3fac99252674c892a4c3801c0a61\n",
      "Successfully built pinyin jieba word2number docopt langdetect pptree sqlitedict wikipedia-api intervaltree\n",
      "Installing collected packages: word2number, wcwidth, sqlitedict, sentencepiece, pptree, pinyin, jieba, docopt, xxhash, terminaltables, segtok, safetensors, pyarrow, num2words, multiprocess, lru-dict, lemminflect, langdetect, jsonlines, intervaltree, ftfy, editdistance, deprecated, conllu, anytree, wikipedia-api, torch, OpenHowNet, language-tool-python, huggingface-hub, bioc, tokenizers, pytorch-revgrad, mpld3, gdown, accelerate, transformers, datasets, bert-score, transformer-smaller-training-vocab, flair, textattack\n",
      "  Attempting uninstall: wcwidth\n",
      "    Found existing installation: wcwidth 0.2.5\n",
      "    Uninstalling wcwidth-0.2.5:\n",
      "      Successfully uninstalled wcwidth-0.2.5\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 14.0.2\n",
      "    Uninstalling pyarrow-14.0.2:\n",
      "      Successfully uninstalled pyarrow-14.0.2\n",
      "Successfully installed OpenHowNet-2.0 accelerate-0.34.2 anytree-2.12.1 bert-score-0.3.13 bioc-2.1 conllu-4.5.3 datasets-3.0.0 deprecated-1.2.14 docopt-0.6.2 editdistance-0.8.1 flair-0.14.0 ftfy-6.2.3 gdown-5.2.0 huggingface-hub-0.24.6 intervaltree-3.1.0 jieba-0.42.1 jsonlines-4.0.0 langdetect-1.0.9 language-tool-python-2.8.1 lemminflect-0.2.3 lru-dict-1.3.0 mpld3-0.5.10 multiprocess-0.70.16 num2words-0.5.13 pinyin-0.4.0 pptree-3.1 pyarrow-17.0.0 pytorch-revgrad-0.2.0 safetensors-0.4.5 segtok-1.5.11 sentencepiece-0.2.0 sqlitedict-2.1.0 terminaltables-3.1.10 textattack-0.3.10 tokenizers-0.19.1 torch-2.4.1 transformer-smaller-training-vocab-0.4.0 transformers-4.44.2 wcwidth-0.2.13 wikipedia-api-0.7.1 word2number-1.1 xxhash-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install keras\n",
    "!pip install tensorflow\n",
    "!pip install Augmentor\n",
    "!pip install tensorflow-io\n",
    "!pip install IPython\n",
    "!pip install textattack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c816035e-7b04-4b7c-a9d3-9e8b7246148f",
   "metadata": {
    "id": "c816035e-7b04-4b7c-a9d3-9e8b7246148f"
   },
   "source": [
    "## Image data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24646b82-a3d7-421f-878a-3ad3c7f726c1",
   "metadata": {
    "id": "24646b82-a3d7-421f-878a-3ad3c7f726c1"
   },
   "source": [
    "### Using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30bf4701-9e1a-4bd8-839c-329e525fa816",
   "metadata": {
    "id": "30bf4701-9e1a-4bd8-839c-329e525fa816"
   },
   "outputs": [],
   "source": [
    "# Importing necessary functions\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c401269c-3e1f-4d0a-9dfa-5811d02891c8",
   "metadata": {
    "id": "c401269c-3e1f-4d0a-9dfa-5811d02891c8"
   },
   "outputs": [],
   "source": [
    "# Initialising the ImageDataGenerator class.\n",
    "# We will pass in the augmentation parameters in the constructor.\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range = 40,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True,\n",
    "    brightness_range = (0.5, 1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6v-tAfHXOtwQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6v-tAfHXOtwQ",
    "outputId": "f3a727e6-e5ea-407f-dc39-4a384b8f2f80"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87fd2ecb-9930-4cb8-865e-2e13e3544de0",
   "metadata": {
    "id": "87fd2ecb-9930-4cb8-865e-2e13e3544de0"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Desktop/Introducción a la Ciencia de Datos/Clases/Notebook ICD - 6/test_image.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Desktop/Introducción a la Ciencia de Datos/Clases/Notebook ICD - 6/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Loading a sample image\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mload_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest_image.jpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# this is a PIL image\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Converting the input sample image to an array\u001b[39;00m\n\u001b[1;32m      5\u001b[0m x \u001b[38;5;241m=\u001b[39m img_to_array(img) \u001b[38;5;66;03m# this is a Numpy array with shape (3, 150, 150)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/keras/src/utils/image_utils.py:235\u001b[0m, in \u001b[0;36mload_img\u001b[0;34m(path, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, pathlib\u001b[38;5;241m.\u001b[39mPath):\n\u001b[1;32m    234\u001b[0m         path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(path\u001b[38;5;241m.\u001b[39mresolve())\n\u001b[0;32m--> 235\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    236\u001b[0m         img \u001b[38;5;241m=\u001b[39m pil_image\u001b[38;5;241m.\u001b[39mopen(io\u001b[38;5;241m.\u001b[39mBytesIO(f\u001b[38;5;241m.\u001b[39mread()))\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Desktop/Introducción a la Ciencia de Datos/Clases/Notebook ICD - 6/test_image.jpg'"
     ]
    }
   ],
   "source": [
    "path = '/Desktop/Introducción a la Ciencia de Datos/Clases/Notebook ICD - 6/'\n",
    "# Loading a sample image\n",
    "img = load_img(path+'test_image.jpg') # this is a PIL image\n",
    "# Converting the input sample image to an array\n",
    "x = img_to_array(img) # this is a Numpy array with shape (3, 150, 150)\n",
    "# Reshaping the input image\n",
    "x = x.reshape((1, ) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6797a15e-8349-4b53-8807-39046d5f67b4",
   "metadata": {
    "id": "6797a15e-8349-4b53-8807-39046d5f67b4"
   },
   "outputs": [],
   "source": [
    "# Generating and saving 5 augmented samples using the above defined parameters.\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size = 1, save_to_dir ='drive/MyDrive/ICD/ICD6/new_images', save_prefix ='image', save_format ='jpg'):\n",
    "    i += 1\n",
    "    if i > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c1eaf2-b0cb-402b-bd18-b97afd7eb165",
   "metadata": {
    "id": "e9c1eaf2-b0cb-402b-bd18-b97afd7eb165"
   },
   "source": [
    "### Using Augmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6a9ef6-5406-4c23-8994-c66cee7a0970",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "df6a9ef6-5406-4c23-8994-c66cee7a0970",
    "outputId": "0eaac827-b6b9-4271-e2a0-6f642605b6f3"
   },
   "outputs": [],
   "source": [
    "# Importing necessary library\n",
    "import Augmentor\n",
    "# Passing the path of the image directory\n",
    "p = Augmentor.Pipeline(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c23986-965c-4a2a-9116-1ba029939be1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a0c23986-965c-4a2a-9116-1ba029939be1",
    "outputId": "0fb13094-28e2-42a8-cddd-f0a94d18a725"
   },
   "outputs": [],
   "source": [
    "# Defining augmentation parameters and generating 5 samples\n",
    "p.flip_left_right(0.5)\n",
    "p.black_and_white(0.1)\n",
    "p.rotate(0.3, 10, 10)\n",
    "p.skew(0.4, 0.5)\n",
    "p.zoom(probability = 0.2, min_factor = 1.1, max_factor = 1.5)\n",
    "p.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4d6d99-d4b0-4076-872e-ccb73a8c6067",
   "metadata": {
    "id": "8e4d6d99-d4b0-4076-872e-ccb73a8c6067"
   },
   "source": [
    "## Audio Data Preparation and Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a43934-fcf3-4fa7-8578-a3aa9432d6f0",
   "metadata": {
    "id": "11a43934-fcf3-4fa7-8578-a3aa9432d6f0"
   },
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "import IPython\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae7950d-b900-4b1d-aa15-91ad71d8f310",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "5ae7950d-b900-4b1d-aa15-91ad71d8f310",
    "outputId": "c296c263-906c-4c5c-d4dd-76bd6b40d2bc"
   },
   "outputs": [],
   "source": [
    "path = 'drive/MyDrive/ICD/ICD6/audios/'\n",
    "#to play the audio\n",
    "IPython.display.Audio(path+\"test_audio.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a307d9-e324-4e0f-9401-1307ca691a99",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "32a307d9-e324-4e0f-9401-1307ca691a99",
    "outputId": "31d6fe84-be3a-4be3-e978-deda1b159d7d"
   },
   "outputs": [],
   "source": [
    "#loading and reading the audio file.\n",
    "audio_data = tfio.audio.AudioIOTensor(path+\"test_audio.wav\")\n",
    "print(audio_data)\n",
    "print(audio_data.shape)\n",
    "print(audio_data.rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f62185-c3d0-409e-8ced-e2d86d825918",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f5f62185-c3d0-409e-8ced-e2d86d825918",
    "outputId": "567dd635-4af0-4484-eb70-5f46609c2e2b"
   },
   "outputs": [],
   "source": [
    "#perform slicing\n",
    "audio_sl = audio_data[5000:]\n",
    "print('Shape After Slicing :',audio_sl.shape)\n",
    "\n",
    "#last dimension is ignored.\n",
    "audio_t = tf.squeeze(audio_sl, axis=[-1])\n",
    "print('Shape After squeezing:',audio_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5297f1d2-39c5-4dd9-961d-2d959127d7b9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "5297f1d2-39c5-4dd9-961d-2d959127d7b9",
    "outputId": "b9962673-8ebe-42e1-8b41-7601e59fb025"
   },
   "outputs": [],
   "source": [
    "#to play the audio,\n",
    "from IPython.display import Audio\n",
    "Audio(audio_t.numpy(), rate=audio_data.rate.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8afe7ed-ad9c-4036-87d2-258d7ec5647c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "id": "a8afe7ed-ad9c-4036-87d2-258d7ec5647c",
    "outputId": "e985815a-edff-4526-edaf-bd751eeb4d8d"
   },
   "outputs": [],
   "source": [
    "# convert tensor to float datatype,.\n",
    "tensor = tf.cast(audio_t, tf.float32) / 32767.0\n",
    "print(tensor)\n",
    "\n",
    "#plot the graph.\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(tensor.numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8788b662-7f03-4d63-ab6a-08cae21d1d9d",
   "metadata": {
    "id": "8788b662-7f03-4d63-ab6a-08cae21d1d9d"
   },
   "source": [
    "### Trimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ad463f-6ac6-4f48-9a37-909ea7c7abe5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e0ad463f-6ac6-4f48-9a37-909ea7c7abe5",
    "outputId": "c88c9908-eee0-4e7d-fd46-7d378016ccee"
   },
   "outputs": [],
   "source": [
    "# Trim silence from the beginning and end of the audio signal\n",
    "trimed = tfio.audio.trim(tensor,\n",
    "                         axis=0,\n",
    "                         epsilon=0.02)\n",
    "print('Trimmed :',trimed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637f8b2f-49c0-4a61-adc5-c0a7a6abbd4a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "637f8b2f-49c0-4a61-adc5-c0a7a6abbd4a",
    "outputId": "841aeb37-8059-49c8-ba7d-5451587a153c"
   },
   "outputs": [],
   "source": [
    "#Mention the stating and ending limit\n",
    "start = trimed[0]\n",
    "stop = trimed[1]\n",
    "print(\"START:{},\\nSTOP :{}\".format(start.numpy(),stop.numpy()))\n",
    "\n",
    "trimmed_audio = tensor[start:stop]\n",
    "print('Trimmed Audio shape:',trimmed_audio.shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(trimmed_audio.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f383ac-07d1-410f-ae35-f659a5e0c7e9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "a7f383ac-07d1-410f-ae35-f659a5e0c7e9",
    "outputId": "1ee493f3-a268-452a-efc1-709b19029d3d"
   },
   "outputs": [],
   "source": [
    "#to play the audio,\n",
    "Audio(trimmed_audio.numpy(), rate=audio_data.rate.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f514f344-1d47-44ef-bbe0-4f0bd10d1e9a",
   "metadata": {
    "id": "f514f344-1d47-44ef-bbe0-4f0bd10d1e9a"
   },
   "source": [
    "### Fade in and out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8ce9d7-ec29-438b-9879-6cddae1d1737",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "1e8ce9d7-ec29-438b-9879-6cddae1d1737",
    "outputId": "ecb31669-28d2-46a2-c305-679e38f29b6a"
   },
   "outputs": [],
   "source": [
    "#Apply a fade-in and fade_out effect with a duration\n",
    "audio_fade = tfio.audio.fade(trimmed_audio, fade_in=20000, fade_out=20000, mode=\"logarithmic\")\n",
    "\n",
    "plt.figure()\n",
    "#plotting the faded audio.\n",
    "plt.plot(audio_fade.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b36d7e-4404-4ffa-9409-573aa7c877a3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "35b36d7e-4404-4ffa-9409-573aa7c877a3",
    "outputId": "fe3a639b-a846-49a3-9f2e-9e2717c973ab"
   },
   "outputs": [],
   "source": [
    "#to plat the audio\n",
    "Audio(audio_fade.numpy(), rate=audio_data.rate.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VgbOgj-ui4SK",
   "metadata": {
    "id": "VgbOgj-ui4SK"
   },
   "source": [
    "### Adding noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6d18df-3f56-474c-8156-bac3c08fd639",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "0a6d18df-3f56-474c-8156-bac3c08fd639",
    "outputId": "6ce1c235-c557-4c34-d1ee-2de2ad5618ef"
   },
   "outputs": [],
   "source": [
    "# adding noise to audio\n",
    "noise_factor = 0.005\n",
    "noise = np.random.randn(len(audio_fade))\n",
    "audio_augmented = audio_fade + noise_factor * noise\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(audio_augmented.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q5tzFyA8buU-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "q5tzFyA8buU-",
    "outputId": "ff91f6a5-ba1b-48b1-c214-b97e816efa7b"
   },
   "outputs": [],
   "source": [
    "Audio(audio_augmented.numpy(), rate=audio_data.rate.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zYdOjee3i7dl",
   "metadata": {
    "id": "zYdOjee3i7dl"
   },
   "source": [
    "### Shifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tdl0irSBcCWw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "tdl0irSBcCWw",
    "outputId": "1e9b26ba-086d-4bbf-82d8-cf2c3ce75ba1"
   },
   "outputs": [],
   "source": [
    "shift_max = 1\n",
    "shift_direction = 'right'\n",
    "shift = np.random.randint(audio_data.rate.numpy() * shift_max)\n",
    "if shift_direction == 'right':\n",
    "    shift = -shift\n",
    "audio_shifted = np.roll(audio_augmented.numpy(), shift)\n",
    "\n",
    "# Set to silence for heading/ tailing\n",
    "#if shift > 0:\n",
    "    #audio_shifted[:shift] = 0\n",
    "#else:\n",
    "    #audio_shifted[shift:] = 0\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(audio_shifted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cq10FsmdKEy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "2cq10FsmdKEy",
    "outputId": "835899ae-10e5-4e2a-fc9c-2b44bbdc80a2"
   },
   "outputs": [],
   "source": [
    "Audio(audio_shifted, rate=audio_data.rate.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tstatX8ci9tA",
   "metadata": {
    "id": "tstatX8ci9tA"
   },
   "source": [
    "### Changing the pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4hUY4UEFeB4z",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "4hUY4UEFeB4z",
    "outputId": "29b508a2-0c49-4b7a-c5b8-37aed022f14b"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "audio_pitch = librosa.effects.pitch_shift(audio_shifted, sr=audio_data.rate.numpy(), n_steps=4)\n",
    "plt.figure()\n",
    "plt.plot(audio_pitch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "__PDANIkeXPR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "__PDANIkeXPR",
    "outputId": "80807693-9c05-4990-f616-a97089164bf5"
   },
   "outputs": [],
   "source": [
    "Audio(audio_pitch, rate=audio_data.rate.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6jRQhEYjAQK",
   "metadata": {
    "id": "a6jRQhEYjAQK"
   },
   "source": [
    "### Changing the speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QACOaBmeewMG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "QACOaBmeewMG",
    "outputId": "6cc532ec-a2a5-4932-d28d-ab27de981d06"
   },
   "outputs": [],
   "source": [
    "audio_speed = librosa.effects.time_stretch(audio_pitch, rate=0.5)\n",
    "plt.figure()\n",
    "plt.plot(audio_speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "S6tqZz-UfrYi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "S6tqZz-UfrYi",
    "outputId": "2f9308c7-fc0e-4c5e-ae44-37b0b382e6cc"
   },
   "outputs": [],
   "source": [
    "Audio(audio_speed, rate=audio_data.rate.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2epCBtx_nOQL",
   "metadata": {
    "id": "2epCBtx_nOQL"
   },
   "source": [
    "## Data augmentation in text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GTdtClp9nQ_P",
   "metadata": {
    "id": "GTdtClp9nQ_P"
   },
   "source": [
    "### Synonym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dTkmxYZwjXaJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dTkmxYZwjXaJ",
    "outputId": "0bf3633a-ae43-423f-8bad-2f532dd829ff"
   },
   "outputs": [],
   "source": [
    "from textattack.augmentation import WordNetAugmenter\n",
    "text = \"start each day with positive thoughts and make your day\"\n",
    "wordnet_aug = WordNetAugmenter()\n",
    "wordnet_aug.augment(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kEh-EqgDnU13",
   "metadata": {
    "id": "kEh-EqgDnU13"
   },
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eueVetzjXpi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6eueVetzjXpi",
    "outputId": "87ba71cb-2d31-4b2e-9c08-ce0b1dea0b21"
   },
   "outputs": [],
   "source": [
    "from textattack.augmentation import EmbeddingAugmenter\n",
    "embed_aug = EmbeddingAugmenter()\n",
    "embed_aug.augment(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qQQdbZvmnsEJ",
   "metadata": {
    "id": "qQQdbZvmnsEJ"
   },
   "source": [
    "### Char swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vmbjTomaj5qQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vmbjTomaj5qQ",
    "outputId": "e0e5a033-75a6-4fdf-bbda-3ea899fa79c2"
   },
   "outputs": [],
   "source": [
    "from textattack.augmentation import CharSwapAugmenter\n",
    "charswap_aug = CharSwapAugmenter()\n",
    "charswap_aug.augment(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Cm4VPQMSnz5Y",
   "metadata": {
    "id": "Cm4VPQMSnz5Y"
   },
   "source": [
    "### Augments words by using the transformation methods, which combines:\n",
    "*   Name Replacement\n",
    "*   Location Replacement\n",
    "*   Number Alteration\n",
    "*   Contraction/Extension\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HHQLa07fj694",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HHQLa07fj694",
    "outputId": "48ae670d-0d9d-45b6-a000-b303d439dd81"
   },
   "outputs": [],
   "source": [
    "from textattack.augmentation import CheckListAugmenter\n",
    "checklist_aug = CheckListAugmenter()\n",
    "checklist_aug.augment(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YYbxUAwGnjgW",
   "metadata": {
    "id": "YYbxUAwGnjgW"
   },
   "source": [
    "### Synonym, deletion, order swaps and random synonym insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "U89WM0drj4e8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U89WM0drj4e8",
    "outputId": "6f7c8027-5334-4778-a0ca-a76970177b66"
   },
   "outputs": [],
   "source": [
    "from textattack.augmentation import EasyDataAugmenter\n",
    "eda_aug = EasyDataAugmenter()\n",
    "eda_aug.augment(text)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
